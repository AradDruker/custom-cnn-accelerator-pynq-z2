{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccaeaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pynq import Overlay, allocate, MMIO\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import json\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import requests\n",
    "from flask import Flask, request, abort\n",
    "\n",
    "# Load the overlay\n",
    "overlay = Overlay('dpu.bit')\n",
    "dma = overlay.axi_dma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58383dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dma.register_map\n",
    "input_size = 784\n",
    "output_size = 1\n",
    "\n",
    "# Allocate image and predict buffers\n",
    "input_buffer = allocate(shape=(input_size,), dtype=np.uint8)\n",
    "output_buffer = allocate(shape=(output_size,), dtype=np.uint8)\n",
    "\n",
    "# Initialize latch to track if initialization is complete\n",
    "init_latch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1abfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(model_info_path):\n",
    "    conv1_list = []\n",
    "    conv2_list = []\n",
    "    fc1_list = []\n",
    "    fc2_list = []\n",
    "    scales = []\n",
    "    labels_mapping = []\n",
    "    \n",
    "    with open(model_info_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    # CONV1     \n",
    "    for channel in range(len(data['conv1']['weights'])):\n",
    "        flatten_list = []\n",
    "        kernel = data['conv1']['weights'][channel][0]\n",
    "        bias = split_32bit_to_signed_8bit(data['conv1']['biases'][channel])\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                flatten_list.append(kernel[i][j])\n",
    "        flatten_list.extend(bias)\n",
    "        conv1_list.extend(flatten_list)\n",
    "        \n",
    "    # CONV2\n",
    "    for channel in range(len(data['conv2']['weights'])):\n",
    "        flatten_list_2 = []\n",
    "        for channel_input in range(len(data['conv2']['weights'][0])):\n",
    "            flatten_list =[]\n",
    "            kernel = data['conv2']['weights'][channel][channel_input]\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    flatten_list.append(kernel[i][j])\n",
    "            flatten_list_2.extend(flatten_list)\n",
    "        bias = list(split_32bit_to_signed_8bit(data['conv2']['biases'][channel]))\n",
    "        flatten_list_2.extend(bias)\n",
    "        conv2_list.extend(flatten_list_2)\n",
    "        \n",
    "    # FC1    \n",
    "    for channel in range(len(data['fc1']['weights'])):\n",
    "        vector = []\n",
    "        vector = data['fc1']['weights'][channel]\n",
    "        bias = list(split_32bit_to_signed_8bit(data['fc1']['biases'][channel]))\n",
    "        vector.extend(bias)\n",
    "        fc1_list.extend(vector)\n",
    "        \n",
    "    # FC2\n",
    "    for channel in range(len(data['fc2']['weights'])):\n",
    "        vector = []\n",
    "        vector = data['fc2']['weights'][channel]\n",
    "        bias = list(split_32bit_to_signed_8bit(data['fc2']['biases'][channel]))\n",
    "        vector.extend(bias)\n",
    "        fc2_list.extend(vector)  \n",
    "     \n",
    "    # effective scale / output scale\n",
    "    for scale in data['Final_Scales']:\n",
    "        scale_vector = []\n",
    "        scale_vector = split_32bit_to_signed_8bit(data['Final_Scales'][scale])\n",
    "        scales.extend(scale_vector)    \n",
    "\n",
    "    # Input scale and input zero point\n",
    "    input_scale = data['quant']['scale']\n",
    "    input_zero_point = data['quant']['zero_point']\n",
    "    output_zero_point = data['fc2']['layer_zero_point']\n",
    "    \n",
    "    scales.append(input_zero_point) \n",
    "    scales.append(output_zero_point) \n",
    "\n",
    "    List = []\n",
    "    List.append(np.array(conv1_list,dtype = np.int8))\n",
    "    List.append(np.array(conv2_list,dtype = np.int8))\n",
    "    List.append(np.array(fc1_list,dtype = np.int8))\n",
    "    List.append(np.array(fc2_list,dtype = np.int8))\n",
    "    List.append(np.array(scales,dtype = np.int8))\n",
    "\n",
    "    labels_mapping = data['label_mapping']\n",
    "\n",
    "    return List, input_scale, input_zero_point, labels_mapping\n",
    "\n",
    "def split_32bit_to_signed_8bit(number):\n",
    "    # Ensure number is a signed 32-bit integer\n",
    "    if number & (1 << 31):  # Check if the sign bit is set\n",
    "        number -= 1 << 32   # Apply two's complement to get the negative value\n",
    "\n",
    "    # Write it as binary\n",
    "    binary_representation = format(number & 0xFFFFFFFF, '032b')  # Pad and keep only the least-significant 32 bits\n",
    "\n",
    "    # Split every 8 bits to 4 8-bit numbers\n",
    "    byte1 = int(binary_representation[0:8], 2)\n",
    "    byte2 = int(binary_representation[8:16], 2)\n",
    "    byte3 = int(binary_representation[16:24], 2)\n",
    "    byte4 = int(binary_representation[24:32], 2)\n",
    "\n",
    "    # Convert those numbers as signed 8-bit integers\n",
    "    byte1 = byte1 - 256 if byte1 > 127 else byte1\n",
    "    byte2 = byte2 - 256 if byte2 > 127 else byte2\n",
    "    byte3 = byte3 - 256 if byte3 > 127 else byte3\n",
    "    byte4 = byte4 - 256 if byte4 > 127 else byte4\n",
    "\n",
    "    # Return the 4 8-bit signed numbers\n",
    "    return byte1, byte2, byte3, byte4\n",
    "\n",
    "def init(lists):\n",
    "    global init_latch  # Declare the global variable\n",
    "    \n",
    "    # Access the custom IP's memory-mapped register\n",
    "    ps_signal = MMIO(0x41200000, 0x1000)\n",
    "    # Start hardware initialization\n",
    "    ps_signal.write(0x00, 0x1)  # Write to control register to start    \n",
    "    \n",
    "    send_start_time = time.time()  # Record start time\n",
    "    for layer in range(len(lists)):\n",
    "        \n",
    "        init_buffer = allocate(shape=(len(lists[layer]),), dtype=np.int8)\n",
    "        init_buffer[:] = lists[layer]\n",
    "\n",
    "        init_buffer.flush()  # Ensure data is flushed to physical memory\n",
    "\n",
    "        # Start DMA transfer and time the operation\n",
    "        dma.sendchannel.transfer(init_buffer)  # Initiate the DMA send\n",
    "\n",
    "        # Wait for DMA transfers to complete\n",
    "        dma.sendchannel.wait()  # Block until send is complete\n",
    "        \n",
    "    send_end_time = time.time()  # Record end time\n",
    "    send_duration = send_end_time - send_start_time\n",
    "    print(f\"Send duration: {send_duration:.6f} seconds\")\n",
    "    \n",
    "    ps_signal.write(0x00, 0x0)  # Reset the control register\n",
    "    # Set initialization latch\n",
    "    init_latch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the initialization function\n",
    "if init_latch == False:\n",
    "    model_info_path = \"model_info.json\"\n",
    "    list, input_scale, input_zero_point, label_mapping = read_json(model_info_path)\n",
    "    init(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffded5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, scale=input_scale, zero_point=input_zero_point):\n",
    "    # Load the image and convert to grayscale\n",
    "    img = image.convert(\"L\")  # Convert to grayscale\n",
    "    # Resize the image using bilinear interpolation (matches PyTorch default)\n",
    "    img = img.resize((28, 28), resample=Image.BILINEAR)\n",
    "    # Convert image to NumPy array with values in [0, 1] (matches ToTensor)\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "    # Normalize to [-1, 1] (matches Normalize((0.5,), (0.5,)))\n",
    "    img_normalized = (img_array - 0.5) / 0.5\n",
    "    # Flatten the normalized array\n",
    "    img_flattened = img_normalized.flatten()\n",
    "    # Quantize the flattened array (matches PyTorch quantization logic)\n",
    "    img_quantized = np.clip(np.round(img_flattened / scale + zero_point), 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img_quantized\n",
    "\n",
    "def predict(image):\n",
    "\n",
    "    input_buffer[:] = image\n",
    "    \n",
    "    input_buffer.flush()\n",
    "    \n",
    "    # Start DMA transfer and time the send operation\n",
    "    dma.sendchannel.transfer(input_buffer)  # Send data\n",
    "    # Time the receive operation\n",
    "    dma.recvchannel.transfer(output_buffer)  # Receive data\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Wait for DMA transfers to complete and record end times\n",
    "    dma.sendchannel.wait()  # Wait for send to complete\n",
    "    \n",
    "    dma.recvchannel.wait()  # Wait for receive to complete\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Invalidate the output buffer to get the latest data\n",
    "    output_buffer.invalidate()\n",
    "\n",
    "    relu_output_fpga = output_buffer[0]\n",
    "    final_predict = label_mapping[str(relu_output_fpga)]\n",
    "     \n",
    "    run_time = end_time - start_time\n",
    "    print(run_time)\n",
    "\n",
    "    return final_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9aa6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_png_images(folder_path):\n",
    "    images = []\n",
    "\n",
    "    # List files only in this folder, sort them, and pick *.png\n",
    "    for file_name in sorted(os.listdir(folder_path)):\n",
    "        if file_name.lower().endswith(\".png\"):\n",
    "            img_path = os.path.join(folder_path, file_name)\n",
    "            img = Image.open(img_path)\n",
    "            images.append(img)\n",
    "            os.remove(img_path)\n",
    "            \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"received_images\"\n",
    "\n",
    "def predict_sequence(folder_path):\n",
    "    images = load_png_images(folder_path)\n",
    "    predictions = []\n",
    "\n",
    "    for img in images:\n",
    "        img_quant = transform(img)      \n",
    "        pred      = predict(img_quant)  \n",
    "        predictions.append(str(pred))\n",
    "\n",
    "    return \" \".join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_DIR = \"/home/xilinx/jupyter_notebooks/project/FinalProject/received_images\"\n",
    "TARGET_URL = \"http://<IP>:5000/receive\"\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def _save_one(file_storage, idx):\n",
    "    filename = file_storage.filename or f\"unnamed_{idx}.png\"\n",
    "    save_path = os.path.join(UPLOAD_DIR, filename)\n",
    "    file_storage.save(save_path)\n",
    "    print(f\"[SERVER] received '{filename}'\")\n",
    "    return save_path\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload():\n",
    "    files = request.files.getlist(\"file\") \n",
    "    if not files:\n",
    "        abort(400, \"No file part called 'file'\")\n",
    "\n",
    "    shutil.rmtree(UPLOAD_DIR, ignore_errors=True)\n",
    "    os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "    for idx, f in enumerate(files, 1):\n",
    "        _save_one(f, idx)\n",
    "\n",
    "    expr_str = predict_sequence(UPLOAD_DIR)\n",
    "    print(\"[SERVER] predicted:\", expr_str)\n",
    "\n",
    "    try:\n",
    "        r = requests.post(TARGET_URL, json={\"text\": expr_str}, timeout=5)\n",
    "        r.raise_for_status()\n",
    "        remote_reply = r.json()   \n",
    "    except Exception as exc:\n",
    "        remote_reply = {\"error\": str(exc)}\n",
    "\n",
    "    return remote_reply, 200\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
