{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccaeaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pynq import Overlay, allocate, MMIO\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import json\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import requests\n",
    "from flask import Flask, request, abort\n",
    "\n",
    "# Load the overlay\n",
    "overlay = Overlay('dpu.bit')\n",
    "dma = overlay.axi_dma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58383dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dma.register_map\n",
    "input_size = 784\n",
    "output_size = 1\n",
    "\n",
    "# Allocate image and predict buffers\n",
    "input_buffer = allocate(shape=(input_size,), dtype=np.uint8)\n",
    "output_buffer = allocate(shape=(output_size,), dtype=np.uint8)\n",
    "\n",
    "# Initialize latch to track if initialization is complete\n",
    "init_latch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1abfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(model_info_path):\n",
    "    conv1_list = []\n",
    "    conv2_list = []\n",
    "    fc1_list = []\n",
    "    fc2_list = []\n",
    "    scales = []\n",
    "    labels_mapping = []\n",
    "    \n",
    "    with open(model_info_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    # CONV1     \n",
    "    for channel in range(len(data['conv1']['weights'])):\n",
    "        flatten_list = []\n",
    "        kernel = data['conv1']['weights'][channel][0]\n",
    "        bias = split_32bit_to_signed_8bit(data['conv1']['biases'][channel])\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                flatten_list.append(kernel[i][j])\n",
    "        flatten_list.extend(bias)\n",
    "        conv1_list.extend(flatten_list)\n",
    "        \n",
    "    # CONV2\n",
    "    for channel in range(len(data['conv2']['weights'])):\n",
    "        flatten_list_2 = []\n",
    "        for channel_input in range(len(data['conv2']['weights'][0])):\n",
    "            flatten_list =[]\n",
    "            kernel = data['conv2']['weights'][channel][channel_input]\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    flatten_list.append(kernel[i][j])\n",
    "            flatten_list_2.extend(flatten_list)\n",
    "        bias = list(split_32bit_to_signed_8bit(data['conv2']['biases'][channel]))\n",
    "        flatten_list_2.extend(bias)\n",
    "        conv2_list.extend(flatten_list_2)\n",
    "        \n",
    "    # FC1    \n",
    "    for channel in range(len(data['fc1']['weights'])):\n",
    "        vector = []\n",
    "        vector = data['fc1']['weights'][channel]\n",
    "        bias = list(split_32bit_to_signed_8bit(data['fc1']['biases'][channel]))\n",
    "        vector.extend(bias)\n",
    "        fc1_list.extend(vector)\n",
    "        \n",
    "    # FC2\n",
    "    for channel in range(len(data['fc2']['weights'])):\n",
    "        vector = []\n",
    "        vector = data['fc2']['weights'][channel]\n",
    "        bias = list(split_32bit_to_signed_8bit(data['fc2']['biases'][channel]))\n",
    "        vector.extend(bias)\n",
    "        fc2_list.extend(vector)  \n",
    "     \n",
    "    # effective scale / output scale\n",
    "    for scale in data['Final_Scales']:\n",
    "        scale_vector = []\n",
    "        scale_vector = split_32bit_to_signed_8bit(data['Final_Scales'][scale])\n",
    "        scales.extend(scale_vector)    \n",
    "\n",
    "    # Input scale and input zero point\n",
    "    input_scale = data['quant']['scale']\n",
    "    input_zero_point = data['quant']['zero_point']\n",
    "    output_zero_point = data['fc2']['layer_zero_point']\n",
    "    \n",
    "    scales.append(input_zero_point) \n",
    "    scales.append(output_zero_point) \n",
    "\n",
    "    List = []\n",
    "    List.append(np.array(conv1_list,dtype = np.int8))\n",
    "    List.append(np.array(conv2_list,dtype = np.int8))\n",
    "    List.append(np.array(fc1_list,dtype = np.int8))\n",
    "    List.append(np.array(fc2_list,dtype = np.int8))\n",
    "    List.append(np.array(scales,dtype = np.int8))\n",
    "\n",
    "    labels_mapping = data['label_mapping']\n",
    "\n",
    "    return List, input_scale, input_zero_point, labels_mapping\n",
    "\n",
    "def split_32bit_to_signed_8bit(number):\n",
    "    # Ensure number is a signed 32-bit integer\n",
    "    if number & (1 << 31):  # Check if the sign bit is set\n",
    "        number -= 1 << 32   # Apply two's complement to get the negative value\n",
    "\n",
    "    # Write it as binary\n",
    "    binary_representation = format(number & 0xFFFFFFFF, '032b')  # Pad and keep only the least-significant 32 bits\n",
    "\n",
    "    # Split every 8 bits to 4 8-bit numbers\n",
    "    byte1 = int(binary_representation[0:8], 2)\n",
    "    byte2 = int(binary_representation[8:16], 2)\n",
    "    byte3 = int(binary_representation[16:24], 2)\n",
    "    byte4 = int(binary_representation[24:32], 2)\n",
    "\n",
    "    # Convert those numbers as signed 8-bit integers\n",
    "    byte1 = byte1 - 256 if byte1 > 127 else byte1\n",
    "    byte2 = byte2 - 256 if byte2 > 127 else byte2\n",
    "    byte3 = byte3 - 256 if byte3 > 127 else byte3\n",
    "    byte4 = byte4 - 256 if byte4 > 127 else byte4\n",
    "\n",
    "    # Return the 4 8-bit signed numbers\n",
    "    return byte1, byte2, byte3, byte4\n",
    "\n",
    "def init(lists):\n",
    "    global init_latch  # Declare the global variable\n",
    "    \n",
    "    # Access the custom IP's memory-mapped register\n",
    "    ps_signal = MMIO(0x41200000, 0x1000)\n",
    "    # Start hardware initialization\n",
    "    ps_signal.write(0x00, 0x1)  # Write to control register to start    \n",
    "    \n",
    "    send_start_time = time.time()  # Record start time\n",
    "    for layer in range(len(lists)):\n",
    "        \n",
    "        init_buffer = allocate(shape=(len(lists[layer]),), dtype=np.int8)\n",
    "        init_buffer[:] = lists[layer]\n",
    "\n",
    "        init_buffer.flush()  # Ensure data is flushed to physical memory\n",
    "\n",
    "        # Start DMA transfer and time the operation\n",
    "        dma.sendchannel.transfer(init_buffer)  # Initiate the DMA send\n",
    "#         print(\"test 1: Sending started\")\n",
    "\n",
    "        # Wait for DMA transfers to complete\n",
    "        dma.sendchannel.wait()  # Block until send is complete\n",
    "#         print(\"test 2: Sending completed\")\n",
    "        \n",
    "    send_end_time = time.time()  # Record end time\n",
    "    send_duration = send_end_time - send_start_time\n",
    "    print(f\"Send duration: {send_duration:.6f} seconds\")\n",
    "    \n",
    "    ps_signal.write(0x00, 0x0)  # Reset the control register\n",
    "    # Set initialization latch\n",
    "    init_latch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the initialization function\n",
    "if init_latch == False:\n",
    "    model_info_path = \"model_info.json\"\n",
    "    list, input_scale, input_zero_point, label_mapping = read_json(model_info_path)\n",
    "    init(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffded5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, scale=input_scale, zero_point=input_zero_point):\n",
    "    # Load the image and convert to grayscale\n",
    "    img = image.convert(\"L\")  # Convert to grayscale\n",
    "    # Resize the image using bilinear interpolation (matches PyTorch default)\n",
    "    img = img.resize((28, 28), resample=Image.BILINEAR)\n",
    "    # Convert image to NumPy array with values in [0, 1] (matches ToTensor)\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "    # Normalize to [-1, 1] (matches Normalize((0.5,), (0.5,)))\n",
    "    img_normalized = (img_array - 0.5) / 0.5\n",
    "    # Flatten the normalized array\n",
    "    img_flattened = img_normalized.flatten()\n",
    "    # Quantize the flattened array (matches PyTorch quantization logic)\n",
    "    img_quantized = np.clip(np.round(img_flattened / scale + zero_point), 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img_quantized\n",
    "\n",
    "def predict_testing(image, label):\n",
    "\n",
    "    input_buffer[:] = image\n",
    "    \n",
    "    input_buffer.flush()\n",
    "    \n",
    "    # Start DMA transfer and time the send operation\n",
    "    dma.sendchannel.transfer(input_buffer)  # Send data\n",
    "    # Time the receive operation\n",
    "    dma.recvchannel.transfer(output_buffer)  # Receive data\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Wait for DMA transfers to complete and record end times\n",
    "    dma.sendchannel.wait()  # Wait for send to complete\n",
    "    \n",
    "    dma.recvchannel.wait()  # Wait for receive to complete\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Invalidate the output buffer to get the latest data\n",
    "    output_buffer.invalidate()\n",
    "\n",
    "    relu_output_fpga = output_buffer[0]\n",
    "    final_predict = label_mapping[str(relu_output_fpga)]\n",
    "#     print(f'final predict: {final_predict}')\n",
    "\n",
    "#     final_predict = np.argmax(output_buffer)\n",
    "#     final_predict = label_mapping[str(final_predict)]\n",
    "     \n",
    "    run_time = end_time - start_time\n",
    "    \n",
    "    if final_predict == label:\n",
    "        return True, run_time\n",
    "#     print(final_predict, label)\n",
    "    return False, run_time\n",
    "\n",
    "def predict(image):\n",
    "\n",
    "    input_buffer[:] = image\n",
    "    \n",
    "    input_buffer.flush()\n",
    "    \n",
    "    # Start DMA transfer and time the send operation\n",
    "    dma.sendchannel.transfer(input_buffer)  # Send data\n",
    "    # Time the receive operation\n",
    "    dma.recvchannel.transfer(output_buffer)  # Receive data\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Wait for DMA transfers to complete and record end times\n",
    "    dma.sendchannel.wait()  # Wait for send to complete\n",
    "    \n",
    "    dma.recvchannel.wait()  # Wait for receive to complete\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Invalidate the output buffer to get the latest data\n",
    "    output_buffer.invalidate()\n",
    "\n",
    "    relu_output_fpga = output_buffer[0]\n",
    "    final_predict = label_mapping[str(relu_output_fpga)]\n",
    "#     print(f'final predict: {final_predict}')\n",
    "\n",
    "#     final_predict = np.argmax(output_buffer)\n",
    "#     final_predict = label_mapping[str(final_predict)]\n",
    "     \n",
    "    run_time = end_time - start_time\n",
    "    \n",
    "#     print(final_predict)\n",
    "#     return run_time\n",
    "    return final_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9aa6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_png_images(folder_path):\n",
    "    images = []\n",
    "\n",
    "    # List files only in this folder, sort them, and pick *.png\n",
    "    for file_name in sorted(os.listdir(folder_path)):\n",
    "        if file_name.lower().endswith(\".png\"):\n",
    "            img_path = os.path.join(folder_path, file_name)\n",
    "            img = Image.open(img_path)\n",
    "            images.append(img)\n",
    "            os.remove(img_path)\n",
    "            \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eff7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "folder_path = \"received_images\"\n",
    "\n",
    "# plt.imshow(images[0], cmap='gray')  # Use the 'gray' colormap\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# img_quant = transform(images[0])\n",
    "# print(predict(img_quant))\n",
    "\n",
    "\n",
    "def predict_sequence(folder_path):\n",
    "    images = load_png_images(folder_path)\n",
    "    predictions = []\n",
    "\n",
    "    for img in images:\n",
    "        img_quant = transform(img)      \n",
    "        pred      = predict(img_quant)  \n",
    "        predictions.append(str(pred))\n",
    "\n",
    "    return \" \".join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_DIR = \"/home/xilinx/jupyter_notebooks/project/FinalProject/received_images\"\n",
    "TARGET_URL = \"http://<IP>:5000/receive\"\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def _save_one(file_storage, idx):\n",
    "    filename = file_storage.filename or f\"unnamed_{idx}.png\"\n",
    "    save_path = os.path.join(UPLOAD_DIR, filename)\n",
    "    file_storage.save(save_path)\n",
    "    print(f\"[SERVER] ✅ received '{filename}'\")\n",
    "    return save_path\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload():\n",
    "    files = request.files.getlist(\"file\") \n",
    "    if not files:\n",
    "        abort(400, \"No file part called 'file'\")\n",
    "\n",
    "    shutil.rmtree(UPLOAD_DIR, ignore_errors=True)\n",
    "    os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "    for idx, f in enumerate(files, 1):\n",
    "        _save_one(f, idx)\n",
    "\n",
    "    expr_str = predict_sequence(UPLOAD_DIR)\n",
    "    print(\"[SERVER] predicted:\", expr_str)\n",
    "\n",
    "    try:\n",
    "        r = requests.post(TARGET_URL, json={\"text\": expr_str}, timeout=5)\n",
    "        r.raise_for_status()\n",
    "        remote_reply = r.json()   \n",
    "    except Exception as exc:\n",
    "        remote_reply = {\"error\": str(exc)}\n",
    "\n",
    "    return remote_reply, 200\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75271f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# def load_images_and_labels(root_directory):\n",
    "#     \"\"\"\n",
    "#     Loads all images from each subfolder inside `root_directory`.\n",
    "#     Returns a list of tuples: (PIL.Image object, label).\n",
    "#     \"\"\"\n",
    "#     data = []\n",
    "#     # Loop over every subfolder (each subfolder is a label name)\n",
    "#     for label_name in os.listdir(root_directory):\n",
    "#         label_folder_path = os.path.join(root_directory, label_name)\n",
    "\n",
    "#         # Only proceed if it's actually a directory\n",
    "#         if os.path.isdir(label_folder_path):\n",
    "#             # For each file in the label folder\n",
    "#             for file_name in os.listdir(label_folder_path):\n",
    "#                 # Check if it's an image by extension\n",
    "#                 if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "#                     img_path = os.path.join(label_folder_path, file_name)\n",
    "                    \n",
    "#                     # Load the image (using Pillow)\n",
    "#                     image = Image.open(img_path)\n",
    "                    \n",
    "#                     # Store it along with its label\n",
    "#                     data.append((image, label_name))\n",
    "                    \n",
    "#     return data\n",
    "\n",
    "# root_directory = \"dataset/image_testing\"\n",
    "# images_and_labels = []\n",
    "# if images_and_labels == []:\n",
    "#     images_and_labels = load_images_and_labels(root_directory)\n",
    "# # # img, label = images_and_labels[736]\n",
    "\n",
    "# # # plt.imshow(img, cmap='gray')  # Use the 'gray' colormap\n",
    "# # # plt.title(f\"Label: {label}\")\n",
    "# # # plt.axis('off')\n",
    "# # # plt.show()\n",
    "\n",
    "# N = len(images_and_labels)\n",
    "# correct_count  = 0\n",
    "# total_time = 0.0\n",
    "\n",
    "# for idx, (img, label) in enumerate(images_and_labels):\n",
    "#     img_quant = transform(img)\n",
    "# #     print(f'label: {label}')\n",
    "#     last_predict, run_time = predict(img_quant, label)\n",
    "    \n",
    "#     if last_predict == True:\n",
    "#         correct_count  += 1\n",
    "        \n",
    "#     total_time += run_time\n",
    "    \n",
    "# avg_time_per_inference_s = total_time / N\n",
    "# print(f\"Average time per inference: {avg_time_per_inference_s * 1000:.3f} ms\")\n",
    "# print(f\"Accuracy: {correct_count/N * 100:.2f}%\")\n",
    "\n",
    "# # # img_quant = transform(img)\n",
    "# # # last_predict, _ = predict(img_quant, label)\n",
    "# # # print(f\"Predict: {last_predict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e23650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_debugging(image):\n",
    "    \n",
    "#     input_buffer[:] = image\n",
    "    \n",
    "#     input_buffer.flush()\n",
    "    \n",
    "#     # Start DMA transfer and time the send operation\n",
    "#     dma.sendchannel.transfer(input_buffer)  # Send data\n",
    "#     # Time the receive operation\n",
    "#     dma.recvchannel.transfer(output_buffer)  # Receive data\n",
    "    \n",
    "#     # Wait for DMA transfers to complete and record end times\n",
    "#     dma.sendchannel.wait()  # Wait for send to complete\n",
    "#     dma.recvchannel.wait()  # Wait for receive to complete\n",
    "    \n",
    "#     # Invalidate the output buffer to get the latest data\n",
    "#     output_buffer.invalidate()\n",
    "\n",
    "#     return output_buffer\n",
    "\n",
    "# # image_path = \"Untitled.png\"\n",
    "# image_path = \"test.png\"\n",
    "# img = Image.open(image_path)\n",
    "# img_quant = transform(img)\n",
    "# label = \"X\"\n",
    "\n",
    "# relu_output_fpga = predict_debugging(img_quant)\n",
    "\n",
    "# relu_output_pytorch = np.array([[0, 34, 65, 46, 18, 18, 30, 49, 31, 0],\n",
    "# [0, 24, 44, 44, 38, 29, 25, 22, 17, 0],\n",
    "# [0, 0, 0, 1, 31, 16, 2, 3, 15, 0],\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "# relu_output_pytorch = relu_output_pytorch.flatten()\n",
    "\n",
    "# # Calculate the difference\n",
    "# difference = relu_output_pytorch - relu_output_fpga\n",
    "# # # Check if matrices are equal\n",
    "# if np.array_equal(relu_output_pytorch, relu_output_fpga):\n",
    "#     print(\"The input and output matrices are identical.\")\n",
    "# else:\n",
    "#     print(\"The input and output matrices are not identical.\")\n",
    "#     for i in range(len(relu_output_fpga)):  # Iterate over all elements\n",
    "#         real = relu_output_pytorch[i]\n",
    "#         fpga = relu_output_fpga[i]\n",
    "#         diff = abs(difference[i])  # Absolute difference\n",
    "#         if real != 0:\n",
    "#             percent_error = (diff / abs(real)) * 100\n",
    "#         else:\n",
    "#             percent_error = 0 if diff == 0 else float('inf')  # Define behavior for zero real value\n",
    "#         print(f'fpga output: {fpga}, real output: {real}, diff: {percent_error:.2f}% : index {i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
