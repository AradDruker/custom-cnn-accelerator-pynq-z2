{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "pth_file_path = \"model.pth\"\n",
    "\n",
    "# Load the checkpoint data\n",
    "checkpoint = torch.load(pth_file_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# checkpoint is typically a dictionary. Let's see its keys:\n",
    "print(\"Keys in the checkpoint:\", checkpoint.keys())\n",
    "\n",
    "# If this .pth file has a model_state_dict (common practice in PyTorch)\n",
    "if \"model_state_dict\" in checkpoint:\n",
    "    model_state = checkpoint[\"model_state_dict\"]\n",
    "    print(\"Number of keys in model_state_dict:\", len(model_state.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create JSON Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_info(pth_file_path):\n",
    "    \"\"\"\n",
    "    Loads a PyTorch .pth checkpoint file and restructures its data into a\n",
    "    hierarchical dictionary ready for JSON serialization.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(pth_file_path, map_location=torch.device('cpu'))\n",
    "    model_info = {}\n",
    "\n",
    "    # Access model_state_dict directly, or use the checkpoint if model_state_dict isn't a key\n",
    "    model_state = checkpoint.get(\"model_state_dict\", checkpoint)\n",
    "\n",
    "    names_list = ['quant', 'conv1', 'conv2', 'fc1', 'fc2']\n",
    "\n",
    "    for layer in range(len(names_list)):\n",
    "        if names_list[layer] == 'quant':\n",
    "            # Handling the 'quant' layer separately as it has different attributes\n",
    "            model_info[names_list[layer]] = {\n",
    "                \"scale\": float(model_state[f'{names_list[layer]}.scale'].item()),\n",
    "                \"zero_point\": int(model_state[f'{names_list[layer]}.zero_point'].item())\n",
    "            }\n",
    "        elif (names_list[layer] == 'conv1' or names_list[layer] == 'conv2'):\n",
    "            # Handling 'conv1' and 'conv2' assuming they are quantized layers\n",
    "            if f'{names_list[layer]}.weight' in model_state:\n",
    "                weights = model_state[f'{names_list[layer]}.weight']\n",
    "                effective_scale = float(model_state[f'{names_list[layer-1]}.scale'])*float(weights.q_scale())\n",
    "                biases_list = model_state[f'{names_list[layer]}.bias'].tolist()\n",
    "                # biases = []\n",
    "\n",
    "                for i in range(len(biases_list)):\n",
    "                    biases_list[i] = round(float(biases_list[i])/effective_scale)\n",
    "\n",
    "                model_info[names_list[layer]] = {\n",
    "                    \"weights\": weights.int_repr().tolist(),\n",
    "                    \"biases\": biases_list,\n",
    "                    \"weights_scale\": float(weights.q_scale()),\n",
    "                    \"weights_zero_point\": int(weights.q_zero_point()),\n",
    "                    \"layer_scale\": float(model_state[f'{names_list[layer]}.scale'].item()),\n",
    "                    \"layer_zero_point\": int(model_state[f'{names_list[layer]}.zero_point'].item())\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            if f'{names_list[layer]}._packed_params._packed_params' in model_state:\n",
    "\n",
    "                weights = model_state[f'{names_list[layer]}._packed_params._packed_params'][0]\n",
    "                # print(weights)\n",
    "                effective_scale = float(model_state[f'{names_list[layer-1]}.scale'])*float(weights.q_scale())\n",
    "                biases_list = model_state[f'{names_list[layer]}._packed_params._packed_params'][1].tolist()\n",
    "                # print(biases_list)\n",
    "                for i in range(len(biases_list)):\n",
    "                    biases_list[i] = round(float(biases_list[i])/effective_scale)\n",
    "\n",
    "\n",
    "                model_info[names_list[layer]] = {\n",
    "                    \"weights\": weights.int_repr().tolist(),\n",
    "                    \"biases\": biases_list,\n",
    "                    \"weights_scale\": float(weights.q_scale()),\n",
    "                    \"weights_zero_point\": int(weights.q_zero_point()),\n",
    "                    \"layer_scale\": float(model_state[f'{names_list[layer]}.scale'].item()),\n",
    "                    \"layer_zero_point\": int(model_state[f'{names_list[layer]}.zero_point'].item())\n",
    "                }\n",
    "\n",
    "    Final_Scales = {}\n",
    "    for layer in range(len(names_list)):\n",
    "        if names_list[layer] == 'quant':\n",
    "            continue\n",
    "        elif names_list[layer] == 'conv1':\n",
    "            effective_scale = model_info[names_list[layer]]['weights_scale'] * model_info[names_list[layer-1]]['scale']\n",
    "            final_scale = round((effective_scale*2**16)/model_info[names_list[layer]]['layer_scale'])\n",
    "            Final_Scales[names_list[layer]] =  final_scale\n",
    "            print(Final_Scales[names_list[layer]])\n",
    "        else:\n",
    "            effective_scale = model_info[names_list[layer]]['weights_scale'] * model_info[names_list[layer-1]]['layer_scale']\n",
    "            final_scale =round((effective_scale*2**16)/model_info[names_list[layer]]['layer_scale'])\n",
    "            Final_Scales[names_list[layer]] = final_scale\n",
    "\n",
    "    model_info['Final_Scales'] = Final_Scales\n",
    "    model_info['label_mapping'] = checkpoint.get(\"labels_mapping\", checkpoint)\n",
    "\n",
    "\n",
    "    return model_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Replace this with the path to your .pth file\n",
    "    pth_file_path = \"model.pth\"\n",
    "\n",
    "    # Build the model info dictionary\n",
    "    model_info_dict = load_model_info(pth_file_path)\n",
    "    print(model_info_dict.keys())\n",
    "\n",
    "    # Convert to JSON string\n",
    "    model_info_json = json.dumps(model_info_dict, indent=4)\n",
    "\n",
    "    # Save to a file\n",
    "    with open(\"model_info.json\", \"w\") as f:\n",
    "        f.write(model_info_json)\n",
    "\n",
    "    # Print to console (for demonstration)\n",
    "    print(\"JSON data has been saved to 'model_info.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
